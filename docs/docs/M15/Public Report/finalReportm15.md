---
title: Public Report 
sidebar_position: 1
---

## SIMPATIA Project Module 15

The **SIMPATIA** project (System for Identification and Monitoring for Assured Protection of Workers using AI) advanced through Module 15 with the goal of delivering a robust, generalizable system for automated PPE verification in industrial environments. Over five sprints we moved from planning and scope definition to dataset curation, comparative benchmarking, dataset merging and final performance optimization. The work focused specifically on the automated detection of the “no-helmet” violation and on producing a deployable model pipeline that balances generalization across environments with high precision in the target Atvos context.

In the first sprint we concentrated on project structuring and planning. This phase established the roadmap for the module: defining sprint deliverables, scheduling partial deliveries, aligning technical and business expectations, and preparing the documentation templates and experiment tracking conventions that would be used throughout the module. The result of this sprint was a clear plan that guided dataset collection, annotation standards, experiment reproducibility, and the cadence of validation and reporting for subsequent sprints.

The second sprint focused on the Atvos dataset and initial modeling. An initial training pipeline and PoC were implemented using the Atvos internal PPE dataset, which is small but highly curated (≈420 annotated images focused on the single class “no-helmet”). Despite the dataset size, the curated quality produced strong validation performance that demonstrated the viability of the approach. The Atvos-trained model produced high metrics on validation (Precision ≈ 0.943, Recall ≈ 0.944, mAP@0.5 ≈ 0.935, mAP@0.5:0.95 ≈ 0.580), validating the choice of architecture and the importance of label quality and context relevance for industrial deployments.

The third sprint carried out a comparative analysis between the Atvos dataset and an external Roboflow no-helmet subset. The Roboflow set was larger and more diverse (~1,325 images) but noisier and more variable in environment types (construction sites vs Atvos industrial environments). When models were trained separately on each dataset the Atvos model maintained superior precision and recall (Atvos P ≈ 0.943, R ≈ 0.944; Roboflow P ≈ 0.728, R ≈ 0.553), and the Roboflow-trained model exhibited lower mAP especially when the stricter mAP@0.5:0.95 metric was used (Roboflow mAP@0.5 ≈ 0.614, mAP@0.5:0.95 ≈ 0.392). This comparison highlighted the trade-off between dataset size/diversity and annotation quality: smaller, well-curated datasets produced higher precision, while larger, noisier datasets were useful for robustness testing but required careful cleaning to be fully beneficial.

In the fourth sprint we implemented a merged dataset pipeline to combine Atvos and Roboflow into a single training source designed to improve generalization. The merge required handling different folder structures and label formats, normalizing class names (e.g., mapping “sem_capacete” → “no-helmet”), remapping label indices, and filtering out problematic or background-only files. The merged dataset grew to approximately 1,745 images and, when used to train a generalist model, produced a combination of robustness and respectable precision (Merged: Precision ≈ 0.901, Recall ≈ 0.882, mAP@0.5 ≈ 0.908, mAP@0.5:0.95 ≈ 0.541). The merged approach traded a modest amount of peak precision for significantly improved cross-environment behavior, producing a model better able to handle both Atvos industrial scenes and more varied construction-like contexts.

The fifth and final sprint concentrated on model generalization and performance optimization. The notebook developed in this sprint implemented a cohesive pipeline of improvements: dataset curating (removing orphan images and tiny/invalid bboxes), background normalization/blurring (preserving bounding boxes while reducing background signal), safe and stable augmentations (brightness/contrast, blur, rotation, scale, JPEG compression and coarse dropout), and a progressive training strategy (train on the merged dataset for generalization, then fine-tune on the Atvos subset for specialization). We also evaluated bounding-box precision by running validation at higher input resolutions (for example imgsz up to 1280) and used a freeze → unfreeze training schedule to accelerate convergence while preserving pre-trained features. This final phase produced the most general and reliable model iteration to date, combining the robustness gained from merged-data training with the precision recovered during Atvos fine-tuning.

Across the five sprints the SIMPATIA system matured from planning into a validated MVP: the team established reproducible training and preprocessing pipelines, implemented data normalization and augmentation strategies to increase resilience, and designed a progressive training workflow that balances generalization and specialization. The final, sprint-complete deliverable is a model and training notebook that support production integration: the detector performs consistently across environments, the annotation and YAML normalization utilities enable reproducible merges of heterogeneous datasets, and the validation procedures quantify both detection accuracy and bounding-box precision. This sprint marks the close of the module: the project reached a stable, documented state and delivered an operational pipeline that can be adopted for pilot deployment and iterative improvement.

